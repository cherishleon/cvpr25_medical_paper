# CVPR2025 medical ai papers
# Partially from https://github.com/MedAIerHHL/CVPR-MIA
## Additions or corrections are welcome in Issues!  
format: Title + Paper Link + Code Link. Your contributions are always welcome!

## Image Segmentation (图像分割)
- Interactive Medical Image Segmentation: A Benchmark Dataset and Baseline [[Paper](https://arxiv.org/abs/2411.12814)] [[Code](https://github.com/uni-medical/IMIS-Bench)]
<p align="center">
  <img src="https://github.com/uni-medical/IMIS-Bench/blob/main/assets/fig1.png" width="50%"/>
</p>

- Steady Progress Beats Stagnation: Mutual Aid of Foundation and Conventional Models in Mixed Domain Semi-Supervised Medical Image Segmentation [[Paper](https://export.arxiv.org/abs/2503.16997)] [[Code](https://dycon25.github.io/)]
<p align="center">
  <img src="https://dycon25.github.io/fig2_main_DyCON.jpg" width="50%"/>
</p>
  
- DyCON: Dynamic Uncertainty-aware Consistency and Contrastive Learning for Semi-supervised Medical Image Segmentation [[Paper](https://arxiv.org/abs/2504.045660)]
- EffiDec3D: An Optimized Decoder for High-Performance and Efficient 3D Medical Image Segmentation
- Test-Time Domain Generalization via Universe Learning: A Multi-Graph Matching Approach for Medical Image Segmentation [[Paper](https://arxiv.org/abs/2503.13012)] [[Code](https://github.com/Yore0/TTDG-MGM)]
- nnWNet: Rethinking the Use of Transformers in Biomedical Image Segmentation and Calling for a Unified Evaluation Benchmark. [Paper][Code]
- Interactive Medical Image Segmentation: A Benchmark Dataset and Baseline. [[Paper](https://arxiv.org/pdf/2411.12814)][[Code](https://github.com/uni-medical/IMIS-Bench)]
- Advancing Generalizable Tumor Segmentation with Anomaly.Aware Open-Vocabulary Attention Maps and Frozen FoundationDiffusion Models.
- LesionLocator: Zero-Shot Universal Tumor Segmentation and Tracking in 3D Whole-Body Imaging. [[Paper](https://arxiv.org/pdf/2502.20985)][[Code](https://github.com/MIC-DKFZ/LesionLocator)]
- Enhancing SAM with Efficient Prompting and Preference Optimization for Semi-supervised Medical Image Segmentation. [[Paper](https://arxiv.org/pdf/2503.04639)][Code]
- Boost the Inference with Co-training: A Depth-guided Mutual Learning Framework for Semi-supervised Medical Polyp Segmentation (RD-Net)  [[Code](https://github.com/pingchuan/RD-Net0)]

## Vision-Language Model (视觉-语言)
* VILA-M3: Enhancing Vision-Language Models with Medical Expert Knowledge   [[paper](https://arxiv.org/abs/2411.12915)]  [[code](https://github.com/Project-MONAI/VLM-Radiology-Agent-Framework)] (based on [[MONAI](https://github.com/Project-MONAI)]

<p align="center">
  <img src="https://github.com/Project-MONAI/VLM-Radiology-Agent-Framework/blob/main/m3/docs/images/VILA-M3_overview_v2.png" width="50%"/>
</p>

*  BIOMEDICA: An Open Biomedical Image-Caption Archive with Vision-Language Models derived from Scientific Literature [[paper](https://arxiv.org/abs/2501.07171v3)]  [[project](https://minwoosun.github.io/biomedica-website/)] 

<p align="center">
  <img src="https://minwoosun.github.io/biomedica-website/images/data_workflow.png" width="50%"/>
</p>

* BiomedCoOp: Learning to Prompt for Biomedical Vision-Language Models [[paper](https://arxiv.org/abs/2411.15232)]  [[code](https://github.com/HealthX-Lab/BiomedCoOp)] 

<p align="center">
    <img src="https://github.com/HealthX-Lab/BiomedCoOp/blob/main/assets/BiomedCoOp.jpg" width="50%"/>
</p>

* MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output
* Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine [[Paper](https://arxiv.org/abs/2412.09278)  [[code](https://github.com/ShawnHuang497/MedPLIB)]  (*AAAI-2025*)

<p align="center">
  <img src="https://github.com/ShawnHuang497/MedPLIB/raw/main/assets/demo.png" width="50%"/>
</p>


* Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis
* Alignment, Mining and Fusion: Representation Alignment with Hard Negative Mining and Selective Knowledge Fusion for Medical Visual Question Answering
* Enhanced Contrastive Learning with Multi-view Longitudinal Data for Chest X-ray Report Generation. [[Paper](https://arxiv.org/abs/2502.20056)][[Code](https://github.com/mk-runner/MLRG)]
<p align="center">
  <img src="https://github.com/mk-runner/MLRG/blob/main/generated-radiology-reports/fig2.png" width="50%"/>
</p>


* MedUnifier: Unifying Vision-and-Language Pre-training on Medical Data with Vision Generation Task using Discrete Visual Representations. [[Paper](https://arxiv.org/pdf/2503.01019)][Code]

##  Multi modality (多模态)
* Multi-modal Medical Diagnosis via Large-small Model Collaboration   [[paper](https://arxiv.org/abs/2412.02621)]  [[code](https://github.com/Zoew420/AdaCoMed/tree/main)]

<p align="center">
  <img src="https://github.com/Zoew420/AdaCoMed/blob/main/figs/image.png?raw=true" width="50%"/>
</p>

* Multi-modal Vision Pre-training for Medical Image Analysis  [[paper](https://arxiv.org/abs/2410.10604) [[code](https://github.com/shaohao011/BrainMVP)]

<p align="center">
  <img src="https://github.com/shaohao011/BrainMVP/raw/main/assets/overview.png" width="50%"/>
</p>

* STiL: Semi-supervised Tabular-Image Learning for Comprehensive Task-Relevant Information Exploration in Multimodal Classification  [[paper](https://arxiv.org/abs/2503.06277)] [[code](https://github.com/siyi-wind/STiL)]
  
<p align="center">
  <img src="https://github.com/siyi-wind/STiL/blob/main/Images/model.jpg" width="50%"/>
</p>
  


## Computational Pathology (计算病理)

- Fast and Accurate Gigapixel Pathological Image Classification with Hierarchical Distillation Multi-Instance LearningComputational Pathology. [[Paper](https://arxiv.org/pdf/2502.21130)][[Code](https://github.com/JiuyangDong/HDMIL)]
- FOCUS: Knowledge-enhanced Adaptive Visual Compression for Few-shot Whole Slide Image Classification. [[Paper](https://arxiv.org/abs/2411.14743)][[Code](https://github.com/dddavid4real/FOCUS)][[推送](https://mp.weixin.qq.com/s/1MYkitZ3btZUBOMcBg_ryw)]
<p align="center">
  <img src="https://github.com/dddavid4real/FOCUS/blob/main/image/method.png" width="50%"/>
</p>

- Distilled Prompt Learning for Incomplete Multimodal Survival Prediction. [[Paper](https://arxiv.org/pdf/2503.01653)] [[Code](https://github.com/Innse/DisPro)]
- Fast and Accurate Gigapixel Pathological Image Classification with Hierarchical Distillation Multi-Instance Learning. [[Paper](https://arxiv.org/abs/2502.21130)][[Code](https://github.com/JiuyangDong/HDMIL.)]
- SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding. [[Paper](https://arxiv.org/abs/2410.11761)][Code]
- 2DMamba: Efficient State Space Model for Image Representation with Applications on Giga-Pixel Whole Slide Image Classification. [[Paper](https://arxiv.org/abs/2412.00678)][Code]
- CPath-Omni: A Unified Multimodal Foundation Model for Patch and Whole Slide Image Analysis in Computational Pathology. [[Paper](https://arxiv.org/abs/2412.12077)][Code]
- MERGE: Multi-faceted Hierarchical Graph-based GNN for Gene Expression Prediction from Whole Slide Histopathology Images. [[Paper](https://arxiv.org/html/2412.02601v1)][Code]
- HistoFS: Non-IID Histopathologic Whole Slide Image Classification via Federated Style Transfer with RoI-Preserving. [Paper][Code]
- M3amba: Memory Mamba is All You Need for Whole Slide Image Classification. [Paper][Code]
- Advancing Multiple Instance Learning with Continual Learning for Whole Slide Imaging. [Paper][Code]
- BioX-CPath: Biologically-driven Explainable Diagnostics for Multistain IHC Computational Pathology. [Paper][Code]
- Multi-Resolution Pathology-Language Pre-training Model with Text-Guided Visual Representation. [Paper][Code]
- TopoCellGen: Generating Histopathology Cell Topology with a Diffusion Model. [[Paper](https://arxiv.org/abs/2412.06011)][Code]
- Multi-modal Topology-embedded Graph Learning for Spatially Resolved Genes Prediction from Pathology Images with Prior Gene Similarity Information. [Paper][Code]
- Robust Multimodal Survival Prediction with the Latent Differentiation Conditional Variational AutoEncoder. [Paper][Code]
- MExD: An Expert-Infused Diffusion Model for Whole-Slide Image Classification. [Paper][Code]
- Learning Heterogeneous Tissues with Mixture of Experts for Gigapixel Whole Slide Images. [Paper][Code]
- Unsupervised Foundation Model-Agnostic Slide-Level Representation Learning. [[Paper](https://arxiv.org/abs/2411.13623)][Code]
- WISE: A Framework for Gigapixel Whole-Slide-Image Lossless Compression. [Paper][Code]

## Others
* Blood Flow Speed Estimation with Optical Coherence Tomography Angiography Images [[Paper](https://www3.cs.stonybrook.edu/~hling/publication/octa-flow-cvpr25.pdf)] [[Code](https://github.com/Spritea/OCTA-Flow)]
  
<figure>
  <img
  src="https://github.com/Spritea/OCTA-Flow/blob/main/assets/samples.gif"
  width="50%"
  title="Samples">
</figure>

* dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis  [[Paper](https://arxiv.org/abs/2503.10412v2)]
* Q-PART: Quasi-Periodic Adaptive Regression with Test-time Training for Pediatric Left Ventricular Ejection Fraction Regression.
* Towards All-in-One Medical Image Re-Identification [[Paper](https://arxiv.org/abs/2503.08173)]
